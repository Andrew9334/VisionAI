import clip
import numpy as np
import torch
import logging
from PIL import Image

# üîπ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CLIPpredictor:

    def __init__(self):
        self.text_descriptions = [
            "This is a photo of a cheap electronic device",
            "This is a photo of an expensive electronic device",
            "This is a photo of a medium-price electronic device",
        ]

        self.class_name = ["Cheap equipment", "Expensive equipment", "Medium-price equipment"]

        self.model, self.preprocess = clip.load("ViT-B/32", device="cpu")  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ
        self.model.eval()

    def preprocess_image(self, path):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ –º–æ–¥–µ–ª—å"""
        image = Image.open(path)
        image = self.preprocess(image).unsqueeze(0)  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –¥–æ–±–∞–≤–ª—è–µ–º batch dimension
        return image

    def predict(self, pred_im):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ CLIP —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–∫–æ–π"""
        try:
            image_input = self.preprocess_image(pred_im)
            text_tokens = clip.tokenize(self.text_descriptions)

            with torch.no_grad():
                image_features = self.model.encode_image(image_input).float()
                text_features = self.model.encode_text(text_tokens).float()
                image_features /= image_features.norm(dim=-1, keepdim=True)
                text_features /= text_features.norm(dim=-1, keepdim=True)

            text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)
            top_probs, top_labels = text_probs.cpu().topk(3, dim=-1)

            # üî• –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∏ –ª–∏ —Å–æ–∑–¥–∞–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
            if top_labels is None or top_labels.nelement() == 0:
                raise ValueError("–û—à–∏–±–∫–∞: `top_labels` –ø—É—Å—Ç –∏–ª–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")

            # üîπ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç
            class_label = str(self.class_name[int(top_labels[0][0].item())])  # –¢–µ–ø–µ—Ä—å —Ç–æ—á–Ω–æ str
            confidence = round(float(top_probs[0][0].item()), 4)  # –¢–µ–ø–µ—Ä—å —Ç–æ—á–Ω–æ float
            full_probs = [round(float(p), 4) for p in text_probs.cpu().numpy()[0]]  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ list[float]

            # üî• –õ–æ–≥–∏—Ä—É–µ–º –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
            logger.info(f"‚úÖ CLIP class_name: {class_label} (type: {type(class_label)})")
            logger.info(f"‚úÖ CLIP confidence: {confidence} (type: {type(confidence)})")
            logger.info(f"‚úÖ CLIP full_probs: {full_probs} (type: {type(full_probs)})")

            return {
                "class": class_label,
                "confidence": confidence,
                "full_probs": full_probs
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ CLIP: {e}")
            return {"error": "–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è CLIP"}
